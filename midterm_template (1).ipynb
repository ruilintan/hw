{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aQoMk--DCfN"
      },
      "source": [
        "This template notebook should serve as a guide for how to load and manipulate the dataset, and the different preprocessing methods you may choose to implement (you are welcome to try any others outside of what is provided here). This code should be treated as pseudo-code - and you may have to debug this code to get it working adequately.\n",
        "\n",
        "In this notebook, we only access the labeled portion of the training dataset, and directly run/train/fit supervised methods. e.g., Multinomial Naive Bayes and Linear SGD classifiers (linear SGD [https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html] implements regularized linear models with stochastic gradient descent, e.g., by choosing loss=‘log_loss’, you obtain a logistic regression classifier), on only this labeled portion of the training dataset. The performance values you get from running this experiment will serve as your baseline.\n",
        "\n",
        "Once you have these baseline numbers for the configuration of preprocessing and supervised methods you choose (ideally at least 2 preprocessing methods and also at least 2 supervised methods), you can now begin working on Part 1: i.e. using unsupervised learning methods to automate adding labels to the unlabelled portion of the train dataset. The goal is to see if adding these newly labeled data examples to the train set will improve the baseline numbers you obtained (i.e. Part 2: running the supervised methods you chose for the baseline on the newly augmented dataset and reporting the performance on this augmented dataset).\n",
        "\n",
        "Lastly, please note that there is a class imbalance in the train, test, and val sets. You will have to incorporate an approach to deal with this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Baseline results\n",
        "\n",
        "BOW NB: 0.506\n",
        "BOW SGD: 0.497\n",
        "\n",
        "CountVectorizer/TFIDF NB: 0.577\n",
        "CountVectorizer/TFIDF SGD: 0.589\n",
        "\n",
        "\n",
        "Our results\n",
        "\n",
        "BOW NB: 0.488\n",
        "BOW SGD: 0.485\n",
        "\n",
        "CountVectorizer/TFIDF NB: 0.520\n",
        "CountVectorizer/TFIDF SGD: 0.534"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LX0ia6JVtFjr"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import os\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression as sk_OLS\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "ORIGINAL_LABEL = 'Sentiment'\n",
        "AUGMENTED_LABEL = 'final_label'\n",
        "NUM_CLASSES = 5\n",
        "UNLABELLED_VALUE = -100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD0dQabauB7z"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "uRBDrBxYtBbk"
      },
      "outputs": [],
      "source": [
        "# Create a folder within MyDrive (default google drive location) called sample_data\n",
        "# Upload all data files there\n",
        "FILE_PATH = \"../data/\"\n",
        "train_data = pd.read_csv(FILE_PATH + \"train.csv\")\n",
        "val_data = pd.read_csv(FILE_PATH + \"val.csv\")\n",
        "test_data = pd.read_csv(FILE_PATH + \"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COVSCAfadeb2",
        "outputId": "81d17027-b82c-4882-9366-bdfecce9705d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Data Shape: (109242,)\n",
            "Cleaned Train Data Shape: (43697,)\n",
            "Validation Data Shape: (23409,)\n",
            "Test Data Shape: (23409,)\n",
            " \n",
            "Number of labels = 0 in train dataset as percentage: 1.75%\n",
            "Number of labels = 1 in train dataset as percentage: 6.91%\n",
            "Number of labels = 2 in train dataset as percentage: 20.52%\n",
            "Number of labels = 3 in train dataset as percentage: 8.46%\n",
            "Number of labels = 4 in train dataset as percentage: 2.37%\n",
            "Number of labels = -100 in train dataset as percentage: 60.00%\n",
            " \n",
            "Number of labels = 0 in val dataset as percentage: 4.52%\n",
            "Number of labels = 1 in val dataset as percentage: 17.47%\n",
            "Number of labels = 2 in val dataset as percentage: 50.61%\n",
            "Number of labels = 3 in val dataset as percentage: 21.33%\n",
            "Number of labels = 4 in val dataset as percentage: 6.08%\n",
            "Number of labels = -100 in val dataset as percentage: 0.00%\n"
          ]
        }
      ],
      "source": [
        "# get all train data (labelled and unlabelled)\n",
        "X_train    = train_data['Phrase']\n",
        "y_train    = train_data['Sentiment']\n",
        "\n",
        "# get only labelled train data\n",
        "mask = (y_train != -100)\n",
        "train_data_clean    = train_data[mask]\n",
        "X_train_clean    = X_train[mask]\n",
        "y_train_clean    = y_train[mask]\n",
        "\n",
        "# get val data\n",
        "X_val    = val_data['Phrase']\n",
        "y_val    = val_data['Sentiment']\n",
        "\n",
        "# get test data\n",
        "X_test     = test_data['Phrase']\n",
        "\n",
        "print(f\"Train Data Shape: {X_train.shape}\")\n",
        "print(f\"Cleaned Train Data Shape: {train_data_clean['Phrase'].shape}\")\n",
        "print(f\"Validation Data Shape: {X_val.shape}\")\n",
        "print(f\"Test Data Shape: {X_test.shape}\")\n",
        "\n",
        "print(\" \")\n",
        "print(f\"Number of labels = 0 in train dataset as percentage: {((y_train == 0).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in train dataset as percentage: {((y_train == 1).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in train dataset as percentage: {((y_train == 2).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in train dataset as percentage: {((y_train == 3).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in train dataset as percentage: {((y_train == 4).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = -100 in train dataset as percentage: {((y_train == -100).sum() / (X_train.shape[0])) * 100:0.2f}%\")\n",
        "\n",
        "print(\" \")\n",
        "print(f\"Number of labels = 0 in val dataset as percentage: {((y_val == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 1 in val dataset as percentage: {((y_val == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 2 in val dataset as percentage: {((y_val == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 3 in val dataset as percentage: {((y_val == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = 4 in val dataset as percentage: {((y_val == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "print(f\"Number of labels = -100 in val dataset as percentage: {((y_val == -100).sum() / (X_val.shape[0])) * 100:0.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xlccu-qCz18"
      },
      "source": [
        "# Define Preprocessing Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_most_common_label(value_counts):\n",
        "    most_common_label = None\n",
        "    most_common_label_freq = 0\n",
        "    for label, cnt in value_counts.to_dict().items():\n",
        "        if label == -100:\n",
        "            continue\n",
        "        elif cnt > most_common_label_freq:\n",
        "            most_common_label = label\n",
        "            most_common_label_freq = cnt\n",
        "\n",
        "    return most_common_label, most_common_label_freq\n",
        "\n",
        "def balance_classes(df, class_label_column_name='final_label'):\n",
        "\n",
        "    cnts = df[class_label_column_name].value_counts()\n",
        "\n",
        "    most_common_label, most_common_label_freq = get_most_common_label(cnts)\n",
        "\n",
        "    df_balanced = df[df[class_label_column_name] == most_common_label]\n",
        "    for i in range(NUM_CLASSES):\n",
        "        if i == most_common_label:\n",
        "            continue\n",
        "\n",
        "        class_i = df[df[class_label_column_name] == i]\n",
        "        class_i_over = class_i.sample(most_common_label_freq, replace=True)\n",
        "\n",
        "        df_balanced = pd.concat([df_balanced, class_i_over], axis=0)\n",
        "\n",
        "    df_balanced = pd.concat([df_balanced, df[df[class_label_column_name] == UNLABELLED_VALUE]], axis=0)\n",
        "\n",
        "    print(df_balanced[class_label_column_name].value_counts())\n",
        "\n",
        "    return df_balanced.sample(frac = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove rows after preprocessing\n",
        "\n",
        "# combine preprocessing for bow and countvec\n",
        "# strategy: append columns then split\n",
        "\n",
        "def remove_rows(df):\n",
        "    df_copy = df.copy()\n",
        "    df_copy = df_copy.apply(lambda text: set(text.split(\" \")))\n",
        "\n",
        "    # remove phrases with small number of words\n",
        "\n",
        "    \n",
        "    \n",
        "    # check by each cluster to remove correlated examples\n",
        "    # could choose to only do for class no 2\n",
        "\n",
        "    # df = df[data['Phrase'].str.len() >0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5v2_Ro6ca5I",
        "outputId": "0ead34e7-f0d3-487c-f057-df90c9880022"
      },
      "outputs": [],
      "source": [
        "# nltk.download('averaged_perceptron_tagger')\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('wordnet')\n",
        "\n",
        "# # includes http removal, some random substitutions, \n",
        "# def clean(text):\n",
        "#     # TODO did not remove stopwords. why is there a need for the preprocessing for BoW and countvec to be different\n",
        "#     text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "#     texter = re.sub(r\"<br />\", \" \", text)\n",
        "#     texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
        "#     texter = re.sub('&#39;', \"\\\"\", texter)\n",
        "#     texter = re.sub('\\n', \" \", texter)\n",
        "#     texter = re.sub(' u ',\" you \", texter)\n",
        "#     texter = re.sub('`',\"\", texter)\n",
        "#     texter = re.sub(' +', ' ', texter)\n",
        "#     texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
        "#     texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
        "#     texter = re.sub('&amp;', 'and', texter)\n",
        "#     texter = re.sub('\\r', ' ',texter)\n",
        "#     #added substitutions\n",
        "\n",
        "#     #***********added substitutions***********\n",
        "#     # remove all the special characters\n",
        "#     texter = re.sub(r'\\W', ' ', texter)\n",
        "#     # remove all single characters\n",
        "#     texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
        "#     # Remove single characters from the start\n",
        "#     texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
        "#     # Remove numbers\n",
        "#     texter = re.sub(r'\\d+', ' ', texter)\n",
        "#     # Converting to Lowercase\n",
        "#     texter = texter.lower()\n",
        "#     # Remove punctuation\n",
        "#     texter = re.sub(r'[^\\w\\s]', ' ', texter)\n",
        "#     # Remove parentheses\n",
        "#     texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
        "#     # Remove single quotes\n",
        "#     texter = re.sub(r'\\'', ' ', texter)\n",
        "#     # Substituting multiple spaces with single space\n",
        "#     texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
        "\n",
        "#     clean = re.compile('<.*?>')\n",
        "#     texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
        "#     texter = re.sub(clean, '', texter)\n",
        "#     if texter == \"\":\n",
        "#         texter = \"\"\n",
        "#     return texter\n",
        "\n",
        "# def clean_dataset(dataset):\n",
        "#     for row in range(dataset.shape[0]):\n",
        "#         dataset[row,0] = clean(dataset[row,0])\n",
        "#     return dataset\n",
        "\n",
        "# def tokenize_lexicon(texts):\n",
        "#     return_texts = []\n",
        "#     for i in range(len(texts)):\n",
        "#         return_texts.append(nltk.word_tokenize(texts[i]))\n",
        "#         return_texts[i] = nltk.pos_tag(return_texts[i])\n",
        "#     return return_texts\n",
        "\n",
        "# def get_wordnet_pos(pos_tag):\n",
        "#     if pos_tag.startswith('J'):\n",
        "#         return wn.ADJ\n",
        "#     elif pos_tag.startswith('V'):\n",
        "#         return wn.VERB\n",
        "#     elif pos_tag.startswith('N'):\n",
        "#         return wn.NOUN\n",
        "#     elif pos_tag.startswith('R'):\n",
        "#         return wn.ADV\n",
        "#     else:\n",
        "#         return wn.NOUN\n",
        "\n",
        "# def lemmatize_texts(texts):\n",
        "#     return_texts = []\n",
        "#     lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#     for i in range(len(texts)):\n",
        "#         return_texts.append([])\n",
        "#         for j in range(len(texts[i])):\n",
        "#                 return_texts[i].append(lemmer.lemmatize(texts[i][j][0], pos=get_wordnet_pos(texts[i][j][1])))\n",
        "#     return return_texts\n",
        "\n",
        "# def stem_texts(texts):\n",
        "#     return_texts = []\n",
        "#     ps = PorterStemmer()\n",
        "#     for i in range(len(texts)):\n",
        "#         return_texts.append([])\n",
        "#         for j in range(len(texts[i])):\n",
        "#                 return_texts[i].append(ps.stem(texts[i][j][0]))\n",
        "#     return return_texts\n",
        "\n",
        "\n",
        "# def backtostring(texts):\n",
        "#     return_texts = []\n",
        "#     for i in range(len(texts)):\n",
        "#         return_texts.append(\" \".join(texts[i]))\n",
        "#     return return_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_XKPAT4grMt"
      },
      "source": [
        "# Preprocess using Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpMOdJ2uipq",
        "outputId": "834f04cb-cdfb-4642-f71a-c53c89ef5969"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/chrystalquek/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<bound method NDFrame.head of 0         every taste often funny collegiate grossout co...\n",
            "1         bunch good actor flailing around caper neither...\n",
            "2                                           vietnam picture\n",
            "3                                                   fincher\n",
            "4                                         pitiful directing\n",
            "                                ...                        \n",
            "109237                                    trademark villain\n",
            "109238    earn share holiday box office pie although mov...\n",
            "109239        moving tale love destruction unexpected place\n",
            "109240                 love reading andor poetry mean check\n",
            "109241                             drag audience enthusiasm\n",
            "Name: Phrase, Length: 109242, dtype: object>\n",
            "<bound method NDFrame.head of 3                                        fincher\n",
            "4                              pitiful directing\n",
            "5                                        version\n",
            "9                                      best film\n",
            "10                         one reason lackluster\n",
            "                           ...                  \n",
            "109232     acted british cast rival gosford park\n",
            "109234                               easy target\n",
            "109235                               headed east\n",
            "109236    give completely tormented persona bibi\n",
            "109240      love reading andor poetry mean check\n",
            "Name: Phrase, Length: 43697, dtype: object>\n"
          ]
        }
      ],
      "source": [
        "# includes lowercase, removal of punctuation, remove of stopwords, lemmatization, url substitution\n",
        "def preprocess(data): # this pre_process is specific to BoW??\n",
        "    preproc_data = data.copy()\n",
        "    preproc_data = preproc_data.str.lower()\n",
        "    punctuation = string.punctuation\n",
        "    mapping = str.maketrans(\"\", \"\", punctuation)\n",
        "    preproc_data = preproc_data.str.translate(mapping)\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    preproc_data = preproc_data.apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in stop_words]))\n",
        "    nltk.download('wordnet')\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    preproc_data = preproc_data.apply(lambda text: ' '.join([lemmatizer.lemmatize(word) for word in text.split()]))\n",
        "    preproc_data = preproc_data.apply(lambda text: re.sub(r'@\\w+', '', re.sub(r'http\\S+|www\\S+', '', text)))\n",
        "\n",
        "    preproc_data =  preproc_data.apply(lambda text: additional_preprocess(text))\n",
        "\n",
        "    return preproc_data\n",
        "\n",
        "def additional_preprocess(text):\n",
        "    texter = re.sub(r\"<br />\", \" \", text)\n",
        "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
        "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
        "    texter = re.sub('\\n', \" \", texter)\n",
        "    texter = re.sub(' u ',\" you \", texter)\n",
        "    texter = re.sub('`',\"\", texter)\n",
        "    texter = re.sub(' +', ' ', texter)\n",
        "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
        "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
        "    texter = re.sub('&amp;', 'and', texter)\n",
        "    texter = re.sub('\\r', ' ',texter)\n",
        "\n",
        "    # remove all single characters\n",
        "    texter = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', texter)\n",
        "    # Remove single characters from the start\n",
        "    texter = re.sub(r'\\^[a-zA-Z]\\s+', ' ', texter)\n",
        "    # Remove numbers\n",
        "    texter = re.sub(r'\\d+', ' ', texter)\n",
        "\n",
        "    # Remove parentheses\n",
        "    texter = re.sub(r'\\([^)]*\\)', ' ', texter)\n",
        "    # Remove single quotes\n",
        "    texter = re.sub(r'\\'', ' ', texter)\n",
        "    # Substituting multiple spaces with single space\n",
        "    texter = re.sub(r'\\s+', ' ', texter, flags=re.I)\n",
        "\n",
        "    clean = re.compile('<.*?>')\n",
        "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
        "    texter = re.sub(clean, '', texter)\n",
        "    if texter == \"\":\n",
        "        texter = \"\"\n",
        "    return texter\n",
        "\n",
        "# get the preprocessed data\n",
        "X_train_preproc = preprocess(X_train) # TODO add remove rows\n",
        "# update y_train\n",
        "\n",
        "# dont remove rows from X_train_clean since it wont be used.\n",
        "X_train_clean_preproc   = preprocess(X_train_clean)\n",
        "X_val_preproc = preprocess(X_val)\n",
        "X_test_preproc = preprocess(X_test)\n",
        "\n",
        "print(X_train_preproc.head)\n",
        "print(X_train_clean_preproc.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GhiuEjdumEO"
      },
      "source": [
        "Bag of words model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-ES4zksi-z2J"
      },
      "outputs": [],
      "source": [
        "combined_data = pd.concat([X_train_preproc, X_val_preproc, X_test_preproc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "sdBuYWZ1-knR",
        "outputId": "f73e2052-aa53-4822-ca3a-5abc58c2c768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment\n",
            "-100.0    193173\n",
            " 2.0       34265\n",
            " 0.0       34265\n",
            " 1.0       34265\n",
            " 3.0       34265\n",
            " 4.0       34265\n",
            "Name: count, dtype: int64\n",
            "<bound method NDFrame.head of                                                    Phrase  Sentiment\n",
            "100721            film ultimately inspiring hallmark card     -100.0\n",
            "5364                                         autocritique        3.0\n",
            "22308   rifkin doubt fancy something hubert selby jr n...     -100.0\n",
            "13101                           close get imitation movie        3.0\n",
            "41486   luminous interview amazingly evocative film th...     -100.0\n",
            "...                                                   ...        ...\n",
            "19424   three lead produce adequate performance missin...        4.0\n",
            "11860         promise new kind high delivers old bad trip     -100.0\n",
            "91078                                   lessthanthrilling     -100.0\n",
            "66935                                          love drive        1.0\n",
            "76704   opaque selfindulgent plain goofy excuse movie ...     -100.0\n",
            "\n",
            "[364498 rows x 2 columns]>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "padding = np.zeros((combined_data.shape[0] - len(y_train) - len(y_val))) # might need to replace y_train if using another var\n",
        "padding[:] = UNLABELLED_VALUE\n",
        "labels = np.concatenate([np.array(y_train), np.array(y_val), padding])\n",
        "combined_data = combined_data.to_frame()\n",
        "combined_data[ORIGINAL_LABEL] = labels\n",
        "\n",
        "combined_data = balance_classes(combined_data, ORIGINAL_LABEL)\n",
        "\n",
        "print(combined_data.head)\n",
        "\n",
        "combined_data = combined_data['Phrase']\n",
        "\n",
        "\n",
        "text_data = combined_data\n",
        "words = ' '.join(text_data).split()\n",
        "word_freq_dict = Counter(words)\n",
        "\n",
        "word_frequencies = list(word_freq_dict.values())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(word_frequencies, bins=55, color='skyblue', edgecolor='black', range=(0, 1000))\n",
        "plt.xlabel('Word Frequency')\n",
        "plt.ylabel('Number of Words that show up X times')\n",
        "plt.title('Distribution of Word Frequencies')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHUe14I09-p-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Should i add max_df? apparently not...\n",
        "\n",
        "action :   2209\n",
        "bad :   3378\n",
        "best :   2779\n",
        "better :   1693\n",
        "character :   5553\n",
        "come :   2014\n",
        "comedy :   4266\n",
        "director :   2339\n",
        "film :   16126\n",
        "feel :   2719\n",
        "good :   4202\n",
        "like :   6039\n",
        "make :   5063\n",
        "performance :   3388"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fD4ZzrPQuo7B"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['act' 'acting' 'action' 'actor' 'actress' 'actually' 'adult' 'adventure'\n",
            " 'age' 'almost' 'already' 'also' 'always' 'ambitious' 'american' 'amusing'\n",
            " 'animation' 'another' 'anyone' 'anything' 'appeal' 'approach' 'around'\n",
            " 'art' 'artist' 'attempt' 'attention' 'audience' 'away' 'awful' 'back'\n",
            " 'bad' 'barely' 'beautiful' 'beautifully' 'beauty' 'become' 'becomes'\n",
            " 'believe' 'best' 'better' 'beyond' 'big' 'bit' 'black' 'bland' 'book'\n",
            " 'boring' 'boy' 'brilliant' 'ca' 'camera' 'capture' 'care' 'cast'\n",
            " 'certainly' 'change' 'character' 'charm' 'charming' 'cheap' 'child'\n",
            " 'cinema' 'cinematic' 'cinematography' 'classic' 'clever' 'cliche' 'cold'\n",
            " 'come' 'comedy' 'comic' 'compelling' 'completely' 'complex' 'concept'\n",
            " 'contrived' 'could' 'creative' 'credit' 'crime' 'culture' 'dark' 'date'\n",
            " 'day' 'de' 'death' 'debut' 'deeply' 'delight' 'delightful' 'despite'\n",
            " 'dialogue' 'different' 'directed' 'direction' 'director' 'documentary'\n",
            " 'done' 'drag' 'drama' 'dramatic' 'dream' 'dry' 'dull' 'dumb' 'earnest'\n",
            " 'easily' 'easy' 'effect' 'effort' 'either' 'element' 'else' 'emotion'\n",
            " 'emotional' 'emotionally' 'end' 'ending' 'energy' 'engaging' 'enjoy'\n",
            " 'enjoyable' 'enough' 'entertaining' 'entertainment' 'entirely' 'epic'\n",
            " 'episode' 'especially' 'even' 'event' 'ever' 'every' 'everyone'\n",
            " 'everything' 'excellent' 'exercise' 'expect' 'experience' 'eye' 'face'\n",
            " 'fact' 'fails' 'fall' 'familiar' 'family' 'fan' 'fantasy' 'far'\n",
            " 'fascinating' 'feature' 'feel' 'feeling' 'film' 'filmmaker' 'filmmaking'\n",
            " 'find' 'fine' 'first' 'fit' 'flat' 'flick' 'formula' 'french' 'fresh'\n",
            " 'full' 'fun' 'funny' 'gag' 'game' 'genre' 'gentle' 'genuine' 'get' 'girl'\n",
            " 'give' 'go' 'going' 'good' 'gorgeous' 'great' 'guy' 'half' 'hand' 'hard'\n",
            " 'head' 'heart' 'help' 'hero' 'high' 'hilarious' 'historical' 'history'\n",
            " 'hold' 'hollywood' 'home' 'honest' 'horror' 'hour' 'human' 'humor' 'idea'\n",
            " 'image' 'imagination' 'imagine' 'impossible' 'inside' 'insight' 'instead'\n",
            " 'intelligence' 'intelligent' 'interest' 'interesting' 'intriguing' 'john'\n",
            " 'joke' 'keep' 'kid' 'kind' 'know' 'lack' 'lacking' 'last' 'laugh' 'le'\n",
            " 'lead' 'least' 'leave' 'left' 'let' 'level' 'life' 'light' 'like'\n",
            " 'likely' 'line' 'little' 'live' 'long' 'look' 'looking' 'lost' 'lot'\n",
            " 'love' 'low' 'lrb' 'made' 'major' 'make' 'making' 'man' 'manages'\n",
            " 'manner' 'many' 'master' 'material' 'matter' 'may' 'mean' 'melodrama'\n",
            " 'memorable' 'memory' 'men' 'mess' 'message' 'might' 'mind' 'minute'\n",
            " 'modern' 'moment' 'moral' 'motion' 'movie' 'moving' 'mr' 'much' 'music'\n",
            " 'must' 'mystery' 'narrative' 'nature' 'nearly' 'need' 'never' 'new'\n",
            " 'next' 'none' 'nothing' 'nt' 'obvious' 'offer' 'often' 'old' 'one'\n",
            " 'opera' 'original' 'otherwise' 'pace' 'part' 'particularly' 'passion'\n",
            " 'past' 'people' 'perfect' 'performance' 'personal' 'picture' 'piece'\n",
            " 'place' 'plain' 'play' 'pleasure' 'plenty' 'plot' 'point' 'political'\n",
            " 'poorly' 'portrait' 'possible' 'power' 'powerful' 'predictable' 'premise'\n",
            " 'pretty' 'probably' 'problem' 'prof' 'project' 'psychological' 'put'\n",
            " 'quality' 'question' 'quirky' 'quite' 'rare' 'rather' 'real' 'reality'\n",
            " 'really' 'reason' 'recent' 'relationship' 'remains' 'remarkable' 'rich'\n",
            " 'ride' 'right' 'rock' 'role' 'romance' 'romantic' 'rrb' 'run' 'running'\n",
            " 'sad' 'satisfying' 'say' 'scene' 'score' 'screen' 'screenplay' 'script'\n",
            " 'second' 'see' 'seeing' 'seem' 'seems' 'seen' 'sense' 'sequel' 'sequence'\n",
            " 'series' 'serious' 'set' 'several' 'sex' 'short' 'shot' 'show' 'side'\n",
            " 'silly' 'simple' 'simply' 'since' 'sit' 'situation' 'slow' 'small'\n",
            " 'smart' 'soap' 'social' 'solid' 'something' 'sometimes' 'sort' 'sound'\n",
            " 'special' 'spirit' 'spy' 'stand' 'star' 'start' 'still' 'story'\n",
            " 'storytelling' 'straight' 'strong' 'study' 'stuff' 'stupid' 'style'\n",
            " 'subject' 'success' 'summer' 'sure' 'surprise' 'surprisingly' 'suspense'\n",
            " 'sweet' 'take' 'taking' 'tale' 'talent' 'talented' 'teen' 'tell' 'term'\n",
            " 'terrific' 'theater' 'theme' 'thing' 'think' 'thinking' 'thoroughly'\n",
            " 'though' 'thought' 'thoughtful' 'three' 'thriller' 'time' 'tired' 'title'\n",
            " 'together' 'tone' 'touch' 'touching' 'tragedy' 'true' 'truly' 'try'\n",
            " 'trying' 'turn' 'tv' 'twist' 'two' 'ugly' 'ultimately' 'unfunny' 'value'\n",
            " 'version' 'video' 'viewer' 'violence' 'vision' 'visual' 'visually' 'want'\n",
            " 'war' 'warm' 'warmth' 'waste' 'watch' 'watching' 'way' 'welcome' 'well'\n",
            " 'whole' 'whose' 'wit' 'without' 'wo' 'woman' 'wonderful' 'word' 'work'\n",
            " 'working' 'world' 'worse' 'worst' 'worth' 'would' 'writerdirector'\n",
            " 'writing' 'written' 'wrong' 'year' 'yet' 'you' 'young']\n",
            "['act' 'acting' 'action' 'actor' 'actress' 'actually' 'adult' 'adventure'\n",
            " 'age' 'almost' 'already' 'also' 'always' 'ambitious' 'american' 'amusing'\n",
            " 'animation' 'another' 'anyone' 'anything' 'appeal' 'approach' 'around'\n",
            " 'art' 'artist' 'attempt' 'attention' 'audience' 'away' 'awful' 'back'\n",
            " 'bad' 'barely' 'beautiful' 'beautifully' 'beauty' 'become' 'becomes'\n",
            " 'believe' 'best' 'better' 'beyond' 'big' 'bit' 'black' 'bland' 'book'\n",
            " 'boring' 'boy' 'brilliant' 'ca' 'camera' 'capture' 'care' 'cast'\n",
            " 'certainly' 'change' 'character' 'charm' 'charming' 'cheap' 'child'\n",
            " 'cinema' 'cinematic' 'cinematography' 'classic' 'clever' 'cliche' 'cold'\n",
            " 'come' 'comedy' 'comic' 'compelling' 'completely' 'complex' 'concept'\n",
            " 'contrived' 'could' 'creative' 'credit' 'crime' 'culture' 'dark' 'date'\n",
            " 'day' 'de' 'death' 'debut' 'deeply' 'delight' 'delightful' 'despite'\n",
            " 'dialogue' 'different' 'directed' 'direction' 'director' 'documentary'\n",
            " 'done' 'drag' 'drama' 'dramatic' 'dream' 'dry' 'dull' 'dumb' 'earnest'\n",
            " 'easily' 'easy' 'effect' 'effort' 'either' 'element' 'else' 'emotion'\n",
            " 'emotional' 'emotionally' 'end' 'ending' 'energy' 'engaging' 'enjoy'\n",
            " 'enjoyable' 'enough' 'entertaining' 'entertainment' 'entirely' 'epic'\n",
            " 'episode' 'especially' 'even' 'event' 'ever' 'every' 'everyone'\n",
            " 'everything' 'excellent' 'exercise' 'expect' 'experience' 'eye' 'face'\n",
            " 'fact' 'fails' 'fall' 'familiar' 'family' 'fan' 'fantasy' 'far'\n",
            " 'fascinating' 'feature' 'feel' 'feeling' 'film' 'filmmaker' 'filmmaking'\n",
            " 'find' 'fine' 'first' 'fit' 'flat' 'flick' 'formula' 'french' 'fresh'\n",
            " 'full' 'fun' 'funny' 'gag' 'game' 'genre' 'gentle' 'genuine' 'get' 'girl'\n",
            " 'give' 'go' 'going' 'good' 'gorgeous' 'great' 'guy' 'half' 'hand' 'hard'\n",
            " 'head' 'heart' 'help' 'hero' 'high' 'hilarious' 'historical' 'history'\n",
            " 'hold' 'hollywood' 'home' 'honest' 'horror' 'hour' 'human' 'humor' 'idea'\n",
            " 'image' 'imagination' 'imagine' 'impossible' 'inside' 'insight' 'instead'\n",
            " 'intelligence' 'intelligent' 'interest' 'interesting' 'intriguing' 'john'\n",
            " 'joke' 'keep' 'kid' 'kind' 'know' 'lack' 'lacking' 'last' 'laugh' 'le'\n",
            " 'lead' 'least' 'leave' 'left' 'let' 'level' 'life' 'light' 'like'\n",
            " 'likely' 'line' 'little' 'live' 'long' 'look' 'looking' 'lost' 'lot'\n",
            " 'love' 'low' 'lrb' 'made' 'major' 'make' 'making' 'man' 'manages'\n",
            " 'manner' 'many' 'master' 'material' 'matter' 'may' 'mean' 'melodrama'\n",
            " 'memorable' 'memory' 'men' 'mess' 'message' 'might' 'mind' 'minute'\n",
            " 'modern' 'moment' 'moral' 'motion' 'movie' 'moving' 'mr' 'much' 'music'\n",
            " 'must' 'mystery' 'narrative' 'nature' 'nearly' 'need' 'never' 'new'\n",
            " 'next' 'none' 'nothing' 'nt' 'obvious' 'offer' 'often' 'old' 'one'\n",
            " 'opera' 'original' 'otherwise' 'pace' 'part' 'particularly' 'passion'\n",
            " 'past' 'people' 'perfect' 'performance' 'personal' 'picture' 'piece'\n",
            " 'place' 'plain' 'play' 'pleasure' 'plenty' 'plot' 'point' 'political'\n",
            " 'poorly' 'portrait' 'possible' 'power' 'powerful' 'predictable' 'premise'\n",
            " 'pretty' 'probably' 'problem' 'prof' 'project' 'psychological' 'put'\n",
            " 'quality' 'question' 'quirky' 'quite' 'rare' 'rather' 'real' 'reality'\n",
            " 'really' 'reason' 'recent' 'relationship' 'remains' 'remarkable' 'rich'\n",
            " 'ride' 'right' 'rock' 'role' 'romance' 'romantic' 'rrb' 'run' 'running'\n",
            " 'sad' 'satisfying' 'say' 'scene' 'score' 'screen' 'screenplay' 'script'\n",
            " 'second' 'see' 'seeing' 'seem' 'seems' 'seen' 'sense' 'sequel' 'sequence'\n",
            " 'series' 'serious' 'set' 'several' 'sex' 'short' 'shot' 'show' 'side'\n",
            " 'silly' 'simple' 'simply' 'since' 'sit' 'situation' 'slow' 'small'\n",
            " 'smart' 'soap' 'social' 'solid' 'something' 'sometimes' 'sort' 'sound'\n",
            " 'special' 'spirit' 'spy' 'stand' 'star' 'start' 'still' 'story'\n",
            " 'storytelling' 'straight' 'strong' 'study' 'stuff' 'stupid' 'style'\n",
            " 'subject' 'success' 'summer' 'sure' 'surprise' 'surprisingly' 'suspense'\n",
            " 'sweet' 'take' 'taking' 'tale' 'talent' 'talented' 'teen' 'tell' 'term'\n",
            " 'terrific' 'theater' 'theme' 'thing' 'think' 'thinking' 'thoroughly'\n",
            " 'though' 'thought' 'thoughtful' 'three' 'thriller' 'time' 'tired' 'title'\n",
            " 'together' 'tone' 'touch' 'touching' 'tragedy' 'true' 'truly' 'try'\n",
            " 'trying' 'turn' 'tv' 'twist' 'two' 'ugly' 'ultimately' 'unfunny' 'value'\n",
            " 'version' 'video' 'viewer' 'violence' 'vision' 'visual' 'visually' 'want'\n",
            " 'war' 'warm' 'warmth' 'waste' 'watch' 'watching' 'way' 'welcome' 'well'\n",
            " 'whole' 'whose' 'wit' 'without' 'wo' 'woman' 'wonderful' 'word' 'work'\n",
            " 'working' 'world' 'worse' 'worst' 'worth' 'would' 'writerdirector'\n",
            " 'writing' 'written' 'wrong' 'year' 'yet' 'you' 'young']\n",
            "['act' 'acting' 'action' 'actor' 'actress' 'actually' 'adult' 'adventure'\n",
            " 'age' 'almost' 'already' 'also' 'always' 'ambitious' 'american' 'amusing'\n",
            " 'animation' 'another' 'anyone' 'anything' 'appeal' 'approach' 'around'\n",
            " 'art' 'artist' 'attempt' 'attention' 'audience' 'away' 'awful' 'back'\n",
            " 'bad' 'barely' 'beautiful' 'beautifully' 'beauty' 'become' 'becomes'\n",
            " 'believe' 'best' 'better' 'beyond' 'big' 'bit' 'black' 'bland' 'book'\n",
            " 'boring' 'boy' 'brilliant' 'ca' 'camera' 'capture' 'care' 'cast'\n",
            " 'certainly' 'change' 'character' 'charm' 'charming' 'cheap' 'child'\n",
            " 'cinema' 'cinematic' 'cinematography' 'classic' 'clever' 'cliche' 'cold'\n",
            " 'come' 'comedy' 'comic' 'compelling' 'completely' 'complex' 'concept'\n",
            " 'contrived' 'could' 'creative' 'credit' 'crime' 'culture' 'dark' 'date'\n",
            " 'day' 'de' 'death' 'debut' 'deeply' 'delight' 'delightful' 'despite'\n",
            " 'dialogue' 'different' 'directed' 'direction' 'director' 'documentary'\n",
            " 'done' 'drag' 'drama' 'dramatic' 'dream' 'dry' 'dull' 'dumb' 'earnest'\n",
            " 'easily' 'easy' 'effect' 'effort' 'either' 'element' 'else' 'emotion'\n",
            " 'emotional' 'emotionally' 'end' 'ending' 'energy' 'engaging' 'enjoy'\n",
            " 'enjoyable' 'enough' 'entertaining' 'entertainment' 'entirely' 'epic'\n",
            " 'episode' 'especially' 'even' 'event' 'ever' 'every' 'everyone'\n",
            " 'everything' 'excellent' 'exercise' 'expect' 'experience' 'eye' 'face'\n",
            " 'fact' 'fails' 'fall' 'familiar' 'family' 'fan' 'fantasy' 'far'\n",
            " 'fascinating' 'feature' 'feel' 'feeling' 'film' 'filmmaker' 'filmmaking'\n",
            " 'find' 'fine' 'first' 'fit' 'flat' 'flick' 'formula' 'french' 'fresh'\n",
            " 'full' 'fun' 'funny' 'gag' 'game' 'genre' 'gentle' 'genuine' 'get' 'girl'\n",
            " 'give' 'go' 'going' 'good' 'gorgeous' 'great' 'guy' 'half' 'hand' 'hard'\n",
            " 'head' 'heart' 'help' 'hero' 'high' 'hilarious' 'historical' 'history'\n",
            " 'hold' 'hollywood' 'home' 'honest' 'horror' 'hour' 'human' 'humor' 'idea'\n",
            " 'image' 'imagination' 'imagine' 'impossible' 'inside' 'insight' 'instead'\n",
            " 'intelligence' 'intelligent' 'interest' 'interesting' 'intriguing' 'john'\n",
            " 'joke' 'keep' 'kid' 'kind' 'know' 'lack' 'lacking' 'last' 'laugh' 'le'\n",
            " 'lead' 'least' 'leave' 'left' 'let' 'level' 'life' 'light' 'like'\n",
            " 'likely' 'line' 'little' 'live' 'long' 'look' 'looking' 'lost' 'lot'\n",
            " 'love' 'low' 'lrb' 'made' 'major' 'make' 'making' 'man' 'manages'\n",
            " 'manner' 'many' 'master' 'material' 'matter' 'may' 'mean' 'melodrama'\n",
            " 'memorable' 'memory' 'men' 'mess' 'message' 'might' 'mind' 'minute'\n",
            " 'modern' 'moment' 'moral' 'motion' 'movie' 'moving' 'mr' 'much' 'music'\n",
            " 'must' 'mystery' 'narrative' 'nature' 'nearly' 'need' 'never' 'new'\n",
            " 'next' 'none' 'nothing' 'nt' 'obvious' 'offer' 'often' 'old' 'one'\n",
            " 'opera' 'original' 'otherwise' 'pace' 'part' 'particularly' 'passion'\n",
            " 'past' 'people' 'perfect' 'performance' 'personal' 'picture' 'piece'\n",
            " 'place' 'plain' 'play' 'pleasure' 'plenty' 'plot' 'point' 'political'\n",
            " 'poorly' 'portrait' 'possible' 'power' 'powerful' 'predictable' 'premise'\n",
            " 'pretty' 'probably' 'problem' 'prof' 'project' 'psychological' 'put'\n",
            " 'quality' 'question' 'quirky' 'quite' 'rare' 'rather' 'real' 'reality'\n",
            " 'really' 'reason' 'recent' 'relationship' 'remains' 'remarkable' 'rich'\n",
            " 'ride' 'right' 'rock' 'role' 'romance' 'romantic' 'rrb' 'run' 'running'\n",
            " 'sad' 'satisfying' 'say' 'scene' 'score' 'screen' 'screenplay' 'script'\n",
            " 'second' 'see' 'seeing' 'seem' 'seems' 'seen' 'sense' 'sequel' 'sequence'\n",
            " 'series' 'serious' 'set' 'several' 'sex' 'short' 'shot' 'show' 'side'\n",
            " 'silly' 'simple' 'simply' 'since' 'sit' 'situation' 'slow' 'small'\n",
            " 'smart' 'soap' 'social' 'solid' 'something' 'sometimes' 'sort' 'sound'\n",
            " 'special' 'spirit' 'spy' 'stand' 'star' 'start' 'still' 'story'\n",
            " 'storytelling' 'straight' 'strong' 'study' 'stuff' 'stupid' 'style'\n",
            " 'subject' 'success' 'summer' 'sure' 'surprise' 'surprisingly' 'suspense'\n",
            " 'sweet' 'take' 'taking' 'tale' 'talent' 'talented' 'teen' 'tell' 'term'\n",
            " 'terrific' 'theater' 'theme' 'thing' 'think' 'thinking' 'thoroughly'\n",
            " 'though' 'thought' 'thoughtful' 'three' 'thriller' 'time' 'tired' 'title'\n",
            " 'together' 'tone' 'touch' 'touching' 'tragedy' 'true' 'truly' 'try'\n",
            " 'trying' 'turn' 'tv' 'twist' 'two' 'ugly' 'ultimately' 'unfunny' 'value'\n",
            " 'version' 'video' 'viewer' 'violence' 'vision' 'visual' 'visually' 'want'\n",
            " 'war' 'warm' 'warmth' 'waste' 'watch' 'watching' 'way' 'welcome' 'well'\n",
            " 'whole' 'whose' 'wit' 'without' 'wo' 'woman' 'wonderful' 'word' 'work'\n",
            " 'working' 'world' 'worse' 'worst' 'worth' 'would' 'writerdirector'\n",
            " 'writing' 'written' 'wrong' 'year' 'yet' 'you' 'young']\n",
            "<bound method NDFrame.head of         act  acting  action  actor  actress  actually  adult  adventure  age  \\\n",
            "0         0       0       0      0        0         0      0          0    0   \n",
            "1         0       0       0      1        0         0      0          0    0   \n",
            "2         0       0       0      0        0         0      0          0    0   \n",
            "3         0       0       0      0        0         0      0          0    0   \n",
            "4         0       0       0      0        0         0      0          0    0   \n",
            "...     ...     ...     ...    ...      ...       ...    ...        ...  ...   \n",
            "109237    0       0       0      0        0         0      0          0    0   \n",
            "109238    0       0       0      0        0         0      0          0    0   \n",
            "109239    0       0       0      0        0         0      0          0    0   \n",
            "109240    0       0       0      0        0         0      0          0    0   \n",
            "109241    0       0       0      0        0         0      0          0    0   \n",
            "\n",
            "        almost  ...  worth  would  writerdirector  writing  written  wrong  \\\n",
            "0            0  ...      0      0               0        0        0      0   \n",
            "1            0  ...      0      0               0        0        0      0   \n",
            "2            0  ...      0      0               0        0        0      0   \n",
            "3            0  ...      0      0               0        0        0      0   \n",
            "4            0  ...      0      0               0        0        0      0   \n",
            "...        ...  ...    ...    ...             ...      ...      ...    ...   \n",
            "109237       0  ...      0      0               0        0        0      0   \n",
            "109238       0  ...      0      0               0        0        0      0   \n",
            "109239       0  ...      0      0               0        0        0      0   \n",
            "109240       0  ...      0      0               0        0        0      0   \n",
            "109241       0  ...      0      0               0        0        0      0   \n",
            "\n",
            "        year  yet  you  young  \n",
            "0          0    0    0      0  \n",
            "1          0    0    0      0  \n",
            "2          0    0    0      0  \n",
            "3          0    0    0      0  \n",
            "4          0    0    0      0  \n",
            "...      ...  ...  ...    ...  \n",
            "109237     0    0    0      0  \n",
            "109238     0    0    0      0  \n",
            "109239     0    0    0      0  \n",
            "109240     0    0    0      0  \n",
            "109241     0    0    0      0  \n",
            "\n",
            "[109242 rows x 500 columns]>\n",
            "['able look' 'absolutely sense' 'absurd plot' ... 'younger audience'\n",
            " 'zerodimensional unlikable' 'zippy jazzy']\n",
            "['able look' 'absolutely sense' 'absurd plot' ... 'younger audience'\n",
            " 'zerodimensional unlikable' 'zippy jazzy']\n",
            "['able look' 'absolutely sense' 'absurd plot' ... 'younger audience'\n",
            " 'zerodimensional unlikable' 'zippy jazzy']\n",
            "<bound method NDFrame.head of         able look  absolutely sense  absurd plot  abundant supply  \\\n",
            "0               0                 0            0                0   \n",
            "1               0                 0            0                0   \n",
            "2               0                 0            0                0   \n",
            "3               0                 0            0                0   \n",
            "4               0                 0            0                0   \n",
            "...           ...               ...          ...              ...   \n",
            "109237          0                 0            0                0   \n",
            "109238          0                 0            0                0   \n",
            "109239          0                 0            0                0   \n",
            "109240          0                 0            0                0   \n",
            "109241          0                 0            0                0   \n",
            "\n",
            "        academy award  accomplished oscar  acerbic laugh  act like  \\\n",
            "0                   0                   0              0         0   \n",
            "1                   0                   0              0         0   \n",
            "2                   0                   0              0         0   \n",
            "3                   0                   0              0         0   \n",
            "4                   0                   0              0         0   \n",
            "...               ...                 ...            ...       ...   \n",
            "109237              0                   0              0         0   \n",
            "109238              0                   0              0         0   \n",
            "109239              0                   0              0         0   \n",
            "109240              0                   0              0         0   \n",
            "109241              0                   0              0         0   \n",
            "\n",
            "        acting amateurish  acting ensemble  ...  you constant  young actor  \\\n",
            "0                       0                0  ...             0            0   \n",
            "1                       0                0  ...             0            0   \n",
            "2                       0                0  ...             0            0   \n",
            "3                       0                0  ...             0            0   \n",
            "4                       0                0  ...             0            0   \n",
            "...                   ...              ...  ...           ...          ...   \n",
            "109237                  0                0  ...             0            0   \n",
            "109238                  0                0  ...             0            0   \n",
            "109239                  0                0  ...             0            0   \n",
            "109240                  0                0  ...             0            0   \n",
            "109241                  0                0  ...             0            0   \n",
            "\n",
            "        young black  young men  young old  young talent  young woman  \\\n",
            "0                 0          0          0             0            0   \n",
            "1                 0          0          0             0            0   \n",
            "2                 0          0          0             0            0   \n",
            "3                 0          0          0             0            0   \n",
            "4                 0          0          0             0            0   \n",
            "...             ...        ...        ...           ...          ...   \n",
            "109237            0          0          0             0            0   \n",
            "109238            0          0          0             0            0   \n",
            "109239            0          0          0             0            0   \n",
            "109240            0          0          0             0            0   \n",
            "109241            0          0          0             0            0   \n",
            "\n",
            "        younger audience  zerodimensional unlikable  zippy jazzy  \n",
            "0                      0                          0            0  \n",
            "1                      0                          0            0  \n",
            "2                      0                          0            0  \n",
            "3                      0                          0            0  \n",
            "4                      0                          0            0  \n",
            "...                  ...                        ...          ...  \n",
            "109237                 0                          0            0  \n",
            "109238                 0                          0            0  \n",
            "109239                 0                          0            0  \n",
            "109240                 0                          0            0  \n",
            "109241                 0                          0            0  \n",
            "\n",
            "[109242 rows x 2000 columns]>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def bag_of_word(data, threshold_M, ngram_range=(1,1)):\n",
        "    vectorizer = CountVectorizer(binary=True, max_features= threshold_M, ngram_range=ngram_range)\n",
        "    vectorizer.fit(combined_data)\n",
        "    print(vectorizer.get_feature_names_out())\n",
        "    X = vectorizer.transform(data)\n",
        "    featurized_data = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "    return featurized_data\n",
        "\n",
        "# get the featurized data\n",
        "BAG_OF_WORDS_NUM_WORDS = 500\n",
        "X_train_bow_preproc_bow   = bag_of_word(X_train_preproc, BAG_OF_WORDS_NUM_WORDS)\n",
        "X_val_bow_preproc_bow = bag_of_word(X_val_preproc, BAG_OF_WORDS_NUM_WORDS)\n",
        "X_test_bow_preproc_bow = bag_of_word(X_test_preproc, BAG_OF_WORDS_NUM_WORDS)\n",
        "print(X_train_bow_preproc_bow.head)\n",
        "\n",
        "NGRAM_RANGE = (2,2)\n",
        "NGRAMS_NUM_WORDS = 2000\n",
        "X_train_ngram_bow_preproc_bow   = bag_of_word(X_train_preproc, NGRAMS_NUM_WORDS, NGRAM_RANGE)\n",
        "X_val_ngram_bow_preproc_bow = bag_of_word(X_val_preproc, NGRAMS_NUM_WORDS, NGRAM_RANGE)\n",
        "X_test_ngram_bow_preproc_bow = bag_of_word(X_test_preproc, NGRAMS_NUM_WORDS, NGRAM_RANGE)\n",
        "print(X_train_ngram_bow_preproc_bow.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6o6quWYA4dm"
      },
      "source": [
        "Sklearn Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "VSmj-gV0ES9I"
      },
      "outputs": [],
      "source": [
        "def run_nb(X, y, X_val, y_val):\n",
        "\n",
        "    clf = MultinomialNB(alpha=1e-3)\n",
        "    clf.fit(X, y)\n",
        "    sk_y = clf.predict(X_val)\n",
        "\n",
        "    print('Accuracy: ', accuracy_score(y_val, sk_y))\n",
        "\n",
        "    print(f\"Number of labels = 0 in val dataset as percentage: {((sk_y == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 1 in val dataset as percentage: {((sk_y == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 2 in val dataset as percentage: {((sk_y == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 3 in val dataset as percentage: {((sk_y == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 4 in val dataset as percentage: {((sk_y == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "\n",
        "def run_sgd(X, y, X_val, y_val):\n",
        "\n",
        "    clf_sgd = SGDClassifier(loss='hinge', penalty='l2',alpha=1e-5, random_state=42)\n",
        "    clf_sgd.fit(X, y)\n",
        "    y_pred = clf_sgd.predict(X_val)\n",
        "    # print(\"Feature Count \\n\",clf_sgd.feature_count_)\n",
        "    # print(\"Class Log Prior \",clf_sgd.class_log_prior_)\n",
        "    print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
        "    # print(clf_sgd.predict_proba(X_test))\n",
        "\n",
        "    print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "\n",
        "\n",
        "def run_knn(X, y, X_val, y_val):\n",
        "\n",
        "    clf = KNeighborsClassifier(n_neighbors=3)\n",
        "    clf.fit(X, y)\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
        "    # print(clf_sgd.predict_proba(X_test))\n",
        "\n",
        "    print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "\n",
        "\n",
        "def run_random_forest(X, y, X_val, y_val):\n",
        "\n",
        "    clf = RandomForestRegressor(random_state=0)\n",
        "    clf.fit(X, y)\n",
        "    y_pred = clf.predict(X_val)\n",
        "\n",
        "    print('Accuracy: ', accuracy_score(y_val, y_pred))\n",
        "    # print(clf_sgd.predict_proba(X_test))\n",
        "\n",
        "    print(f\"Number of labels = 0 in val dataset as percentage: {((y_pred == 0).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 1 in val dataset as percentage: {((y_pred == 1).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 2 in val dataset as percentage: {((y_pred == 2).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 3 in val dataset as percentage: {((y_pred == 3).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "    print(f\"Number of labels = 4 in val dataset as percentage: {((y_pred == 4).sum() / (X_val.shape[0])) * 100:0.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwgerXc2HPeP",
        "outputId": "fde5b0d6-fcb3-4ebf-86c5-9f1b0ce5fdac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['character' 'film' 'like' 'make' 'movie' 'nt' 'one' 'story']\n",
            "['character' 'film' 'like' 'make' 'movie' 'nt' 'one' 'story']\n",
            "Accuracy:  0.5060874022811739\n",
            "Number of labels = 0 in val dataset as percentage: 0.00%\n",
            "Number of labels = 1 in val dataset as percentage: 0.00%\n",
            "Number of labels = 2 in val dataset as percentage: 100.00%\n",
            "Number of labels = 3 in val dataset as percentage: 0.00%\n",
            "Number of labels = 4 in val dataset as percentage: 0.00%\n",
            "Accuracy:  0.497201930881285\n",
            "Number of labels = 0 in val dataset as percentage: 0.30%\n",
            "Number of labels = 1 in val dataset as percentage: 0.63%\n",
            "Number of labels = 2 in val dataset as percentage: 90.08%\n",
            "Number of labels = 3 in val dataset as percentage: 9.00%\n",
            "Number of labels = 4 in val dataset as percentage: 0.00%\n"
          ]
        }
      ],
      "source": [
        "baseline_X = bag_of_word(X_train_clean_preproc, 8)\n",
        "baseline_X_val = bag_of_word(X_val_preproc, 8)\n",
        "\n",
        "run_nb(baseline_X, y_train_clean, baseline_X_val, y_val)\n",
        "run_sgd(baseline_X, y_train_clean, baseline_X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X71WprhUHBe_"
      },
      "source": [
        "Sklearn Linear SGD Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSQOZqupuKGO"
      },
      "source": [
        "# Preprocess the data using CountVectorizer, nltk stem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4LDKgHgiMpa",
        "outputId": "f91986be-e128-49d5-9d85-c22f345a5b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364498, 500)\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "  (0, 479)\t0.3078034712181961\n",
            "  (0, 427)\t0.436070562942296\n",
            "  (0, 238)\t0.6961569791832173\n",
            "  (0, 161)\t0.30817796934203595\n",
            "  (0, 148)\t0.2189286386979145\n",
            "  (0, 63)\t0.2959079889861254\n",
            "  (1, 294)\t0.5580472878106492\n",
            "  (1, 171)\t0.44882816160104094\n",
            "  (1, 161)\t0.4644525718650557\n",
            "  (1, 4)\t0.5209801478069424\n",
            "  (2, 307)\t1.0\n",
            "  (5, 465)\t1.0\n",
            "  (7, 467)\t0.7154483695359313\n",
            "  (7, 294)\t0.6986656070885254\n",
            "  (8, 436)\t1.0\n",
            "  (9, 148)\t0.5634818835433191\n",
            "  (9, 30)\t0.8261284203551367\n",
            "  (10, 343)\t1.0\n",
            "  (11, 487)\t1.0\n",
            "  (12, 78)\t1.0\n",
            "  (13, 374)\t0.7431646298361848\n",
            "  (13, 120)\t0.6691086107355415\n",
            "  (14, 168)\t1.0\n",
            "  (15, 345)\t0.7237010792707015\n",
            "  (15, 78)\t0.6901135760600727\n",
            "  :\t:\n",
            "  (109225, 91)\t0.4801385251447017\n",
            "  (109225, 57)\t0.5419355903934289\n",
            "  (109225, 2)\t0.446053885472473\n",
            "  (109226, 482)\t0.5516308688379405\n",
            "  (109226, 433)\t0.5386742425965793\n",
            "  (109226, 305)\t0.4241604830956561\n",
            "  (109226, 4)\t0.4749961362876126\n",
            "  (109228, 97)\t1.0\n",
            "  (109232, 47)\t1.0\n",
            "  (109233, 248)\t0.7145595538704445\n",
            "  (109233, 49)\t0.6995746164437867\n",
            "  (109234, 105)\t1.0\n",
            "  (109236, 67)\t1.0\n",
            "  (109238, 435)\t0.506937684786787\n",
            "  (109238, 304)\t0.6668397215159076\n",
            "  (109238, 277)\t0.33711066454276456\n",
            "  (109238, 249)\t0.4297619915757261\n",
            "  (109239, 424)\t0.504092685520596\n",
            "  (109239, 309)\t0.5183347868134333\n",
            "  (109239, 278)\t0.5299045938387553\n",
            "  (109239, 244)\t0.44319378900464057\n",
            "  (109240, 259)\t0.7914409844339104\n",
            "  (109240, 244)\t0.6112455874346109\n",
            "  (109241, 96)\t0.792545034842124\n",
            "  (109241, 21)\t0.6098133876417413\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Shape of passed values is (109242, 1), indices imply (109242, 500)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/chrystalquek/Library/Mobile Documents/com~apple~CloudDocs/AY 2023:2024 Sem 1/AML/midterm proj/Midterm-Project/midterm_template.ipynb Cell 25\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m NGRAM_RANGE \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39m# TODO test different ngram range\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m X_train_cntvec_preproc_cntvec \u001b[39m=\u001b[39m count_vectorizer(X_train_preproc, TFIDF_NUM_WORDS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m X_val_cntvec_preproc_cntvec \u001b[39m=\u001b[39m count_vectorizer(X_val_preproc, TFIDF_NUM_WORDS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m X_test_cntvec_preproc_cntvec \u001b[39m=\u001b[39m count_vectorizer(X_test_preproc, TFIDF_NUM_WORDS)\n",
            "\u001b[1;32m/Users/chrystalquek/Library/Mobile Documents/com~apple~CloudDocs/AY 2023:2024 Sem 1/AML/midterm proj/Midterm-Project/midterm_template.ipynb Cell 25\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(df_data)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# df_data = df_data.todense()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# print(tfidf_vectorizer.get_feature_names_out())\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#X32sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdf_data, columns\u001b[39m=\u001b[39mtfidf_vectorizer\u001b[39m.\u001b[39mget_feature_names_out())\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/pandas/core/frame.py:798\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    790\u001b[0m         mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    791\u001b[0m             arrays,\n\u001b[1;32m    792\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    795\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    799\u001b[0m             data,\n\u001b[1;32m    800\u001b[0m             index,\n\u001b[1;32m    801\u001b[0m             columns,\n\u001b[1;32m    802\u001b[0m             dtype\u001b[39m=\u001b[39mdtype,\n\u001b[1;32m    803\u001b[0m             copy\u001b[39m=\u001b[39mcopy,\n\u001b[1;32m    804\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    805\u001b[0m         )\n\u001b[1;32m    806\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    808\u001b[0m         {},\n\u001b[1;32m    809\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    813\u001b[0m     )\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/pandas/core/internals/construction.py:337\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    333\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[1;32m    334\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[1;32m    335\u001b[0m )\n\u001b[0;32m--> 337\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/pandas/core/internals/construction.py:408\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    406\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[1;32m    407\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[0;32m--> 408\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (109242, 1), indices imply (109242, 500)"
          ]
        }
      ],
      "source": [
        "def count_vectorizer(df, max_features=500, ngram_range=(1,1)):    \n",
        "    # train set\n",
        "    # train = clean_dataset(np.array(train_df))\n",
        "    # val = clean_dataset(np.array(val_data))\n",
        "    # test = clean_dataset(np.expand_dims(np.array(test_data[\"Phrase\"]), axis = 1))\n",
        "    # print(train[:,0].shape)\n",
        "    # print(val[:,0].shape)\n",
        "    # print(test[:,0].shape)\n",
        "    # print(np.concatenate((train[:,0], test[:,0], val[:,0])).shape)\n",
        "\n",
        "    # token_texts = tokenize_lexicon(np.concatenate((train[:,0], val[:,0], test[:,0])))\n",
        "    # data = clean_dataset(combined_data[:,0])\n",
        "    # remove rows from train\n",
        "    # token_texts = tokenize_lexicon(data.to_numpy())\n",
        "\n",
        "    # del train\n",
        "    # del val\n",
        "    # del test\n",
        "\n",
        "    # if(lemma):\n",
        "    #     lemm_texts = lemmatize_texts(token_texts)\n",
        "    # else:\n",
        "    #     lemm_texts = stem_texts(token_texts)\n",
        "    # del token_texts\n",
        "    # processed_texts = backtostring(lemm_texts)\n",
        "    # del lemm_texts\n",
        "\n",
        "    # matrix counts\n",
        "    vectorizer = CountVectorizer(input='content', stop_words='english', min_df=5, max_features = max_features, ngram_range=ngram_range) # colab will crash\n",
        "    X = vectorizer.fit_transform(combined_data)\n",
        "    # print(vectorizer.get_feature_names_out())\n",
        "    # del processed_texts\n",
        "    # del vectorizer\n",
        "    X_dense = X.todense()\n",
        "    print(X_dense.shape)\n",
        "    del X\n",
        "\n",
        "    # tfidf\n",
        "    tfidf_vectorizer = TfidfTransformer()\n",
        "    X_tfidf = tfidf_vectorizer.fit(np.array(X_dense))\n",
        "    del X_dense\n",
        "\n",
        "    # transform only the data\n",
        "    df_data = np.array(df)\n",
        "    df_data = vectorizer.transform(df_data).todense()\n",
        "    print(df_data)\n",
        "    df_data = tfidf_vectorizer.transform(np.array(df_data))\n",
        "    print(df_data)\n",
        "    # df_data = df_data.todense()\n",
        "\n",
        "    # print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "    return pd.DataFrame(data=df_data, columns=tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "    # X_data = pd.DataFrame(data=X_data, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "    # X_train = X_data.iloc[:train_df['Phrase'].shape[0]]\n",
        "    # X_val = X_data.iloc[train_df['Phrase'].shape[0]:train_df['Phrase'].shape[0]+val_data['Phrase'].shape[0]]\n",
        "    # X_test = X_data.iloc[train_df['Phrase'].shape[0]+val_data['Phrase'].shape[0]:]\n",
        "    # del X_data\n",
        "    # print(\"X_train.shape: \", X_train.shape)\n",
        "    # print(\"X_val.shape: \", X_val.shape)\n",
        "    # print(\"X_test.shape: \", X_test.shape)\n",
        "\n",
        "    # return X_train, X_val, X_test\n",
        "\n",
        "TFIDF_NUM_WORDS = 500\n",
        "NGRAM_RANGE = (1,1)\n",
        "# TODO test different ngram range\n",
        "\n",
        "X_train_cntvec_preproc_cntvec = count_vectorizer(X_train_preproc, TFIDF_NUM_WORDS)\n",
        "X_val_cntvec_preproc_cntvec = count_vectorizer(X_val_preproc, TFIDF_NUM_WORDS)\n",
        "X_test_cntvec_preproc_cntvec = count_vectorizer(X_test_preproc, TFIDF_NUM_WORDS)\n",
        "\n",
        "print(X_train_cntvec_preproc_cntvec.head)\n",
        "\n",
        "\n",
        "NGRAM_RANGE = (2,2)\n",
        "NGRAM_NUM_WORDS = 2000\n",
        "X_train_ngram_cntvec_preproc_cntvec = count_vectorizer(X_train_preproc, NGRAM_NUM_WORDS, NGRAM_RANGE)\n",
        "X_val_ngram_cntvec_preproc_cntvec = count_vectorizer(X_val_preproc, NGRAM_NUM_WORDS, NGRAM_RANGE)\n",
        "X_test_ngram_cntvec_preproc_cntvec = count_vectorizer(X_test_preproc, NGRAM_NUM_WORDS, NGRAM_RANGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZyTz60oE2Ml"
      },
      "source": [
        "Sklearn Multinomial NB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuPqD9lShdPQ",
        "outputId": "6672ca85-b124-4f87-ee43-ce87a2597370"
      },
      "outputs": [],
      "source": [
        "# baseline_X = count_vectorizer(X_train_clean_preproc, 7000)\n",
        "# baseline_X_val = bag_of_word(X_val_preproc, 7000)\n",
        "\n",
        "# run_nb(baseline_X, y_train_clean, baseline_X_val, y_val)\n",
        "# run_sgd(baseline_X, y_train_clean, baseline_X_val, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZRRGm7AFXTY"
      },
      "source": [
        "# Part 1: Now that you have your baseline numbers, run your (at least 2) unsupervised algorithms on the unlabelled portion of your train dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWxksSMCq2Mf"
      },
      "source": [
        "Unsupervised/Data Augmentation Method 1: K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zGOPQsN_D7f",
        "outputId": "31569535-cd2e-44b0-a9e3-46e6fadf84c4"
      },
      "outputs": [],
      "source": [
        "# unlabelled data processed using BOW\n",
        "# X_unlabled = train_data[train_data[\"Sentiment\"]==-100][\"Phrase\"]\n",
        "# X_unlabled_preproc   = preprocess_for_bow(X_unlabled)\n",
        "# X_unlabled_processed_bog   = bag_of_word(X_unlabled_preproc, 8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "LiQtrpoBKM7V",
        "outputId": "f2c6216b-f720-4477-d147-5403f8de4ac6"
      },
      "outputs": [],
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# pca = PCA(n_components=0.9)\n",
        "# X_pca = pca.fit_transform(X_unlabled_processed_bog)\n",
        "\n",
        "# print(\"Number of Principal Components: \", pca.n_components_)\n",
        "# print(\"Total Variance Explained by components: \" , sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# # Plot the clusters\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.scatter(X_pca[:, 0], X_pca[:, 1], s=50, alpha = 0.7, c='r')\n",
        "# plt.xlabel('First Principal Component')\n",
        "# plt.ylabel('Second Principal Component')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFsXq6n1Bv6u",
        "outputId": "3f412395-dcf7-4b1b-c3b6-bf48ba98c0be"
      },
      "outputs": [],
      "source": [
        "\n",
        "# diff = []\n",
        "# # check 10 clusters\n",
        "# c = range(1, 11)\n",
        "\n",
        "# for n in c:\n",
        "#     kmeans = KMeans(n_clusters=n, random_state=0).fit(X_unlabled_processed_bog)\n",
        "#     diff.append(kmeans.inertia_)  # Inertia: Sum of squared distances of samples to their closest cluster center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# df_balanced = balance_classes(df_copy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tugRJsRd_Nnv",
        "outputId": "9ea3523c-d0b4-4160-eb06-a38bf0b5ab1e"
      },
      "outputs": [],
      "source": [
        "def pseudo_labelling(df, clustering_model, num_clusters):\n",
        "    CLUSTER_PRED = 'cluster_pred'\n",
        "\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    df_copy[ORIGINAL_LABEL] = y_train\n",
        "\n",
        "    # print(df_copy[ORIGINAL_LABEL].value_counts(CLUSTER_PRED))\n",
        "\n",
        "    # df_balanced = balance_classes(df_copy, ORIGINAL_LABEL) # TODO make sure this is korek\n",
        "\n",
        "    print(df_copy[ORIGINAL_LABEL].value_counts()) # should already be balanced\n",
        "\n",
        "    df_balanced_without_label = df_balanced.drop(ORIGINAL_LABEL, axis=1)\n",
        "\n",
        "    cluster_pred = clustering_model.fit_predict(df_balanced_without_label)\n",
        "    df_balanced[CLUSTER_PRED] = cluster_pred\n",
        "    df_balanced[AUGMENTED_LABEL] = df_balanced[ORIGINAL_LABEL]\n",
        "\n",
        "    # print(X_combined_processed_bog['Sentiment'])\n",
        "    # print(X_combined_processed_bog['predicted_init'])\n",
        "    # print(X_combined_processed_bog_copy['Sentiment'].value_counts())\n",
        "\n",
        "    print(\"original label counts:   \", df_balanced[AUGMENTED_LABEL].value_counts())\n",
        "\n",
        "    m = df_balanced\n",
        "\n",
        "    for cluster_id in range(num_clusters):\n",
        "    \n",
        "        # print(X_combined_processed_bog[X_combined_processed_bog['predicted_init'] == cluster_id])\n",
        "        # for each predicted cluster, most common ground truth cluster is...\n",
        "        \n",
        "        counts = m[m[CLUSTER_PRED] == cluster_id][ORIGINAL_LABEL].value_counts(ascending=False)\n",
        "        most_common_label, _ = get_most_common_label(counts)\n",
        "        print(\"for predicted cluster: \", cluster_id, \", the most common label is: \", most_common_label)\n",
        "        print(counts)\n",
        "\n",
        "        print(\"relabelled \", len(m[(m[AUGMENTED_LABEL] == -100) & (m[CLUSTER_PRED] == cluster_id)]), \" as \", most_common_label)\n",
        "        m.loc[(m[AUGMENTED_LABEL] == -100) & (m[CLUSTER_PRED] == cluster_id), AUGMENTED_LABEL] = most_common_label\n",
        "        \n",
        "\n",
        "    df_balanced = df_balanced.drop(CLUSTER_PRED, axis=1)\n",
        "    df_balanced = df_balanced.drop(ORIGINAL_LABEL, axis=1)\n",
        "\n",
        "    return df_balanced\n",
        "\n",
        "\n",
        "# TODO should double the number of ground truth labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment\n",
            "-100    65545\n",
            " 2      22418\n",
            " 0      22418\n",
            " 1      22418\n",
            " 3      22418\n",
            " 4      22418\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original label counts:    final_label\n",
            "-100    65545\n",
            " 4      22418\n",
            " 1      22418\n",
            " 0      22418\n",
            " 3      22418\n",
            " 2      22418\n",
            "Name: count, dtype: int64\n",
            "for predicted cluster:  0 , the most common label is:  4\n",
            "Sentiment\n",
            "-100    786\n",
            " 4      447\n",
            " 3      387\n",
            " 0      255\n",
            " 2      234\n",
            " 1      153\n",
            "Name: count, dtype: int64\n",
            "relabelled  786  as  4\n",
            "for predicted cluster:  1 , the most common label is:  0\n",
            "Sentiment\n",
            "-100    2785\n",
            " 0      2331\n",
            " 4      1399\n",
            " 1      1214\n",
            " 3      1006\n",
            " 2       647\n",
            "Name: count, dtype: int64\n",
            "relabelled  2785  as  0\n",
            "for predicted cluster:  2 , the most common label is:  2\n",
            "Sentiment\n",
            "-100    58426\n",
            " 2      20708\n",
            " 1      19767\n",
            " 3      19616\n",
            " 0      17947\n",
            " 4      17270\n",
            "Name: count, dtype: int64\n",
            "relabelled  58426  as  2\n",
            "for predicted cluster:  3 , the most common label is:  4\n",
            "Sentiment\n",
            " 4      688\n",
            "-100    457\n",
            " 0      316\n",
            " 1      119\n",
            " 2      113\n",
            " 3      109\n",
            "Name: count, dtype: int64\n",
            "relabelled  457  as  4\n",
            "for predicted cluster:  4 , the most common label is:  4\n",
            "Sentiment\n",
            "-100    3091\n",
            " 4      2614\n",
            " 0      1569\n",
            " 3      1300\n",
            " 1      1165\n",
            " 2       716\n",
            "Name: count, dtype: int64\n",
            "relabelled  3091  as  4\n",
            "final label counts for bow kmeans:     final_label\n",
            "2    80844\n",
            "4    26752\n",
            "0    25203\n",
            "1    22418\n",
            "3    22418\n",
            "Name: count, dtype: int64\n",
            "Sentiment\n",
            "-100    65545\n",
            " 2      22418\n",
            " 0      22418\n",
            " 1      22418\n",
            " 3      22418\n",
            " 4      22418\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/chrystalquek/Library/Mobile Documents/com~apple~CloudDocs/AY 2023:2024 Sem 1/AML/midterm proj/Midterm-Project/midterm_template.ipynb Cell 35\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinal label counts for bow kmeans:    \u001b[39m\u001b[39m\"\u001b[39m, X_train_bow_preproc_bow_kmeans[AUGMENTED_LABEL]\u001b[39m.\u001b[39mvalue_counts())\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# X_train_count_vect, X_val_count_vect, X_test_count_vect \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# X_train_cntvec_preproc_cntvec, X_val_cntvec_preproc_cntvec, X_test_cntvec_preproc_cntvec\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_train_cntvec_preproc_cntvec_kmeans \u001b[39m=\u001b[39m pseudo_labelling(X_train_cntvec_preproc_cntvec, KMeans(n_clusters\u001b[39m=\u001b[39mNUM_K_MEANS_CLUSTERS, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m), NUM_K_MEANS_CLUSTERS)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinal label counts for cntvec kmeans\u001b[39m\u001b[39m\"\u001b[39m, X_train_cntvec_preproc_cntvec_kmeans[AUGMENTED_LABEL]\u001b[39m.\u001b[39mvalue_counts())\n",
            "\u001b[1;32m/Users/chrystalquek/Library/Mobile Documents/com~apple~CloudDocs/AY 2023:2024 Sem 1/AML/midterm proj/Midterm-Project/midterm_template.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# print(X_combined_processed_bog_balanced[ORIGINAL_LABEL].value_counts())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m df_balanced_without_label \u001b[39m=\u001b[39m df_balanced\u001b[39m.\u001b[39mdrop(ORIGINAL_LABEL, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m cluster_pred \u001b[39m=\u001b[39m clustering_model\u001b[39m.\u001b[39mfit_predict(df_balanced_without_label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df_balanced[CLUSTER_PRED] \u001b[39m=\u001b[39m cluster_pred\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chrystalquek/Library/Mobile%20Documents/com~apple~CloudDocs/AY%202023%3A2024%20Sem%201/AML/midterm%20proj/Midterm-Project/midterm_template.ipynb#Y114sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m df_balanced[AUGMENTED_LABEL] \u001b[39m=\u001b[39m df_balanced[ORIGINAL_LABEL]\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1033\u001b[0m, in \u001b[0;36m_BaseKMeans.fit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_predict\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1011\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \n\u001b[1;32m   1013\u001b[0m \u001b[39m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, sample_weight\u001b[39m=\u001b[39msample_weight)\u001b[39m.\u001b[39mlabels_\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1417\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute k-means clustering.\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \n\u001b[1;32m   1392\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[39m    Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m-> 1417\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(\n\u001b[1;32m   1418\u001b[0m     X,\n\u001b[1;32m   1419\u001b[0m     accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1420\u001b[0m     dtype\u001b[39m=\u001b[39m[np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32],\n\u001b[1;32m   1421\u001b[0m     order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1422\u001b[0m     copy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_x,\n\u001b[1;32m   1423\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   1424\u001b[0m )\n\u001b[1;32m   1426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params_vs_input(X)\n\u001b[1;32m   1428\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[1;32m    922\u001b[0m             array,\n\u001b[1;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39minput_name,\n\u001b[1;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[1;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    926\u001b[0m         )\n\u001b[1;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nKMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ],
      "source": [
        "NUM_K_MEANS_CLUSTERS = 5\n",
        "X_train_bow_preproc_bow_kmeans = pseudo_labelling(X_train_bow_preproc_bow, KMeans(n_clusters=NUM_K_MEANS_CLUSTERS, random_state=0), NUM_K_MEANS_CLUSTERS)\n",
        "\n",
        "print(\"final label counts for bow kmeans:    \", X_train_bow_preproc_bow_kmeans[AUGMENTED_LABEL].value_counts())\n",
        "# X_train_count_vect, X_val_count_vect, X_test_count_vect \n",
        "# X_train_cntvec_preproc_cntvec, X_val_cntvec_preproc_cntvec, X_test_cntvec_preproc_cntvec\n",
        "X_train_cntvec_preproc_cntvec_kmeans = pseudo_labelling(X_train_cntvec_preproc_cntvec, KMeans(n_clusters=NUM_K_MEANS_CLUSTERS, random_state=0), NUM_K_MEANS_CLUSTERS)\n",
        "\n",
        "print(\"final label counts for cntvec kmeans\", X_train_cntvec_preproc_cntvec_kmeans[AUGMENTED_LABEL].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_GMM_CLUSTERS = 5\n",
        "X_train_bow_preproc_bow_gmm = pseudo_labelling(X_train_bow_preproc_bow, GaussianMixture(n_components=NUM_GMM_CLUSTERS, random_state=0), NUM_GMM_CLUSTERS)\n",
        "print(\"final label counts for bow gmm:    \", X_train_bow_preproc_bow_gmm[AUGMENTED_LABEL].value_counts())\n",
        "X_train_cntvec_preproc_cntvec_gmm = pseudo_labelling(X_train_cntvec_preproc_cntvec, GaussianMixture(n_components=NUM_GMM_CLUSTERS, random_state=0), NUM_GMM_CLUSTERS)\n",
        "print(\"final label counts for cntvec gmm\", X_train_cntvec_preproc_cntvec_gmm[AUGMENTED_LABEL].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment\n",
            "-100    65545\n",
            " 2      22418\n",
            " 0      22418\n",
            " 1      22418\n",
            " 3      22418\n",
            " 4      22418\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original label counts:    final_label\n",
            "-100    65545\n",
            " 0      22418\n",
            " 4      22418\n",
            " 2      22418\n",
            " 3      22418\n",
            " 1      22418\n",
            "Name: count, dtype: int64\n",
            "for predicted cluster:  0 , the most common label is:  2\n",
            "Sentiment\n",
            "-100    65518\n",
            " 2      22418\n",
            " 3      22418\n",
            " 1      22415\n",
            " 4      22390\n",
            " 0      22253\n",
            "Name: count, dtype: int64\n",
            "relabelled  65518  as  2\n",
            "for predicted cluster:  1 , the most common label is:  0\n",
            "Sentiment\n",
            " 0      82\n",
            "-100     4\n",
            " 1       3\n",
            "Name: count, dtype: int64\n",
            "relabelled  4  as  0\n",
            "for predicted cluster:  2 , the most common label is:  0\n",
            "Sentiment\n",
            " 0      36\n",
            "-100     9\n",
            "Name: count, dtype: int64\n",
            "relabelled  9  as  0\n",
            "for predicted cluster:  3 , the most common label is:  0\n",
            "Sentiment\n",
            " 0      47\n",
            "-100     6\n",
            "Name: count, dtype: int64\n",
            "relabelled  6  as  0\n",
            "for predicted cluster:  4 , the most common label is:  4\n",
            "Sentiment\n",
            " 4      28\n",
            "-100     8\n",
            "Name: count, dtype: int64\n",
            "relabelled  8  as  4\n",
            "final label counts for ngram bow kmeans:     final_label\n",
            "2    87936\n",
            "0    22437\n",
            "4    22426\n",
            "3    22418\n",
            "1    22418\n",
            "Name: count, dtype: int64\n",
            "Sentiment\n",
            "-100    65545\n",
            " 2      22418\n",
            " 0      22418\n",
            " 1      22418\n",
            " 3      22418\n",
            " 4      22418\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chrystalquek/opt/anaconda3/envs/aml/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original label counts:    final_label\n",
            "-100    65545\n",
            " 4      22418\n",
            " 0      22418\n",
            " 3      22418\n",
            " 1      22418\n",
            " 2      22418\n",
            "Name: count, dtype: int64\n",
            "for predicted cluster:  0 , the most common label is:  2\n",
            "Sentiment\n",
            "-100    65233\n",
            " 2      22299\n",
            " 0      22290\n",
            " 1      22286\n",
            " 3      22283\n",
            " 4      22280\n",
            "Name: count, dtype: int64\n",
            "relabelled  65233  as  2\n",
            "for predicted cluster:  1 , the most common label is:  3\n",
            "Sentiment\n",
            "-100    47\n",
            " 3      31\n",
            " 4      28\n",
            " 0      23\n",
            " 1      22\n",
            " 2      17\n",
            "Name: count, dtype: int64\n",
            "relabelled  47  as  3\n",
            "for predicted cluster:  2 , the most common label is:  4\n",
            "Sentiment\n",
            "-100    62\n",
            " 4      53\n",
            " 1      38\n",
            " 2      21\n",
            " 3      21\n",
            "Name: count, dtype: int64\n",
            "relabelled  62  as  4\n",
            "for predicted cluster:  3 , the most common label is:  0\n",
            "Sentiment\n",
            " 0      38\n",
            "-100    15\n",
            " 1      11\n",
            " 2       9\n",
            " 3       3\n",
            "Name: count, dtype: int64\n",
            "relabelled  15  as  0\n",
            "for predicted cluster:  4 , the most common label is:  3\n",
            "Sentiment\n",
            "-100    188\n",
            " 3       80\n",
            " 2       72\n",
            " 0       67\n",
            " 1       61\n",
            " 4       57\n",
            "Name: count, dtype: int64\n",
            "relabelled  188  as  3\n",
            "final label counts for cntvec kmeans final_label\n",
            "2    87651\n",
            "3    22653\n",
            "4    22480\n",
            "0    22433\n",
            "1    22418\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "X_train_ngram_bow_preproc_bow_kmeans = pseudo_labelling(X_train_ngram_bow_preproc_bow, KMeans(n_clusters=NUM_K_MEANS_CLUSTERS, random_state=0), NUM_K_MEANS_CLUSTERS)\n",
        "print(\"final label counts for ngram bow kmeans:    \", X_train_ngram_bow_preproc_bow_kmeans[AUGMENTED_LABEL].value_counts())\n",
        "X_train_ngram_cntvec_preproc_cntvec_kmeans = pseudo_labelling(X_train_ngram_cntvec_preproc_cntvec, KMeans(n_clusters=NUM_K_MEANS_CLUSTERS, random_state=0), NUM_K_MEANS_CLUSTERS)\n",
        "print(\"final label counts for cntvec kmeans\", X_train_ngram_cntvec_preproc_cntvec_kmeans[AUGMENTED_LABEL].value_counts())\n",
        "\n",
        "\n",
        "\n",
        "# EPS = 0.5\n",
        "# MIN_SAMPLES = 10000\n",
        "# X_train_bow_preproc_bow_dbscan = pseudo_labelling(X_train_bow_preproc_bow, DBSCAN(eps=EPS, min_samples=MIN_SAMPLES))\n",
        "# print(\"final label counts for bow dbscan:    \", X_train_bow_preproc_bow_dbscan[AUGMENTED_LABEL].value_counts())\n",
        "# X_train_cntvec_preproc_cntvec_dbscan = pseudo_labelling(X_train_cntvec_preproc_cntvec, DBSCAN(eps=EPS, min_samples=MIN_SAMPLES))\n",
        "# print(\"final label counts for cntvec dbscan\", X_train_cntvec_preproc_cntvec_dbscan[AUGMENTED_LABEL].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# don't class balance again...\n",
        "\n",
        "# print(X_combined_processed_bog_balanced[AUGMENTED_LABEL].value_counts())\n",
        "\n",
        "# X_combined_processed_bog_balanced = balance_classes(X_combined_processed_bog_balanced, AUGMENTED_LABEL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Snf4y2YYB7VP",
        "outputId": "813be5cc-1584-4d06-b219-d7237af0974d"
      },
      "outputs": [],
      "source": [
        "# 3 is optimal number of clusters\n",
        "# KMeans(n_clusters=3, random_state=0).fit(X_unlabled_processed_bog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "eRjFlyRoEGnX",
        "outputId": "b8880b65-3935-436e-8631-4cbc80314256"
      },
      "outputs": [],
      "source": [
        "# # Plot sum of squared distances to find the elbow\n",
        "# plt.plot(c, diff, 'bx-')\n",
        "# plt.xlabel('No. of clusters')\n",
        "# plt.ylabel('Sum of Squared Distances')\n",
        "# plt.title('Optimal number of clusters')\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP9nwgkeq7AP"
      },
      "source": [
        "GMM with Bag of Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnvyM4VvFj-A"
      },
      "source": [
        "# Part 2: With your newly augmented dataset, re-run your supervised algorithms. How do the performance values change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6QLp6NJFu-s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.4992097056687599\n",
            "Number of labels = 0 in val dataset as percentage: 7.47%\n",
            "Number of labels = 1 in val dataset as percentage: 1.21%\n",
            "Number of labels = 2 in val dataset as percentage: 83.89%\n",
            "Number of labels = 3 in val dataset as percentage: 1.41%\n",
            "Number of labels = 4 in val dataset as percentage: 6.02%\n",
            "Accuracy:  0.49271647656884104\n",
            "Number of labels = 0 in val dataset as percentage: 10.24%\n",
            "Number of labels = 1 in val dataset as percentage: 0.69%\n",
            "Number of labels = 2 in val dataset as percentage: 78.53%\n",
            "Number of labels = 3 in val dataset as percentage: 0.68%\n",
            "Number of labels = 4 in val dataset as percentage: 9.87%\n",
            "Accuracy:  0.4933999743688325\n",
            "Number of labels = 0 in val dataset as percentage: 0.64%\n",
            "Number of labels = 1 in val dataset as percentage: 1.06%\n",
            "Number of labels = 2 in val dataset as percentage: 96.17%\n",
            "Number of labels = 3 in val dataset as percentage: 2.04%\n",
            "Number of labels = 4 in val dataset as percentage: 0.09%\n",
            "Accuracy:  0.47028920500662136\n",
            "Number of labels = 0 in val dataset as percentage: 1.07%\n",
            "Number of labels = 1 in val dataset as percentage: 2.13%\n",
            "Number of labels = 2 in val dataset as percentage: 89.26%\n",
            "Number of labels = 3 in val dataset as percentage: 5.59%\n",
            "Number of labels = 4 in val dataset as percentage: 1.96%\n"
          ]
        }
      ],
      "source": [
        "X = X_train_bow_preproc_bow_kmeans.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_bow_preproc_bow_kmeans[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_bow_preproc_bow, y_val)\n",
        "run_sgd(X, y, X_val_bow_preproc_bow, y_val)\n",
        "run_knn(X, y, X_val_bow_preproc_bow, y_val)\n",
        "# run_random_forest(X, y, X_val_bow_preproc_bow, y_val)\n",
        "\n",
        "X = X_train_cntvec_preproc_cntvec_kmeans.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_cntvec_preproc_cntvec_kmeans[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_cntvec_preproc_cntvec, y_val)\n",
        "run_sgd(X, y, X_val_cntvec_preproc_cntvec, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.47148532615660643\n",
            "Number of labels = 0 in val dataset as percentage: 3.68%\n",
            "Number of labels = 1 in val dataset as percentage: 2.35%\n",
            "Number of labels = 2 in val dataset as percentage: 74.41%\n",
            "Number of labels = 3 in val dataset as percentage: 1.64%\n",
            "Number of labels = 4 in val dataset as percentage: 17.93%\n",
            "Accuracy:  0.4614464522192319\n",
            "Number of labels = 0 in val dataset as percentage: 6.34%\n",
            "Number of labels = 1 in val dataset as percentage: 1.99%\n",
            "Number of labels = 2 in val dataset as percentage: 69.05%\n",
            "Number of labels = 3 in val dataset as percentage: 0.82%\n",
            "Number of labels = 4 in val dataset as percentage: 21.80%\n",
            "Accuracy:  0.11405869537357427\n",
            "Number of labels = 0 in val dataset as percentage: 7.52%\n",
            "Number of labels = 1 in val dataset as percentage: 6.83%\n",
            "Number of labels = 2 in val dataset as percentage: 0.00%\n",
            "Number of labels = 3 in val dataset as percentage: 29.45%\n",
            "Number of labels = 4 in val dataset as percentage: 56.20%\n",
            "Accuracy:  0.14673843393566577\n",
            "Number of labels = 0 in val dataset as percentage: 4.58%\n",
            "Number of labels = 1 in val dataset as percentage: 8.41%\n",
            "Number of labels = 2 in val dataset as percentage: 3.10%\n",
            "Number of labels = 3 in val dataset as percentage: 42.23%\n",
            "Number of labels = 4 in val dataset as percentage: 41.68%\n"
          ]
        }
      ],
      "source": [
        "X = X_train_bow_preproc_bow_gmm.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_bow_preproc_bow_gmm[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_bow_preproc_bow, y_val)\n",
        "run_sgd(X, y, X_val_bow_preproc_bow, y_val)\n",
        "\n",
        "X = X_train_cntvec_preproc_cntvec_gmm.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_cntvec_preproc_cntvec_gmm[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_cntvec_preproc_cntvec, y_val)\n",
        "run_sgd(X, y, X_val_cntvec_preproc_cntvec, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5240292195309496\n",
            "Number of labels = 0 in val dataset as percentage: 1.20%\n",
            "Number of labels = 1 in val dataset as percentage: 1.11%\n",
            "Number of labels = 2 in val dataset as percentage: 94.94%\n",
            "Number of labels = 3 in val dataset as percentage: 1.12%\n",
            "Number of labels = 4 in val dataset as percentage: 1.63%\n",
            "Accuracy:  0.5226195053184672\n",
            "Number of labels = 0 in val dataset as percentage: 3.31%\n",
            "Number of labels = 1 in val dataset as percentage: 0.81%\n",
            "Number of labels = 2 in val dataset as percentage: 91.74%\n",
            "Number of labels = 3 in val dataset as percentage: 0.92%\n",
            "Number of labels = 4 in val dataset as percentage: 3.21%\n",
            "Accuracy:  0.5164253065060447\n",
            "Number of labels = 0 in val dataset as percentage: 3.64%\n",
            "Number of labels = 1 in val dataset as percentage: 2.25%\n",
            "Number of labels = 2 in val dataset as percentage: 89.91%\n",
            "Number of labels = 3 in val dataset as percentage: 1.54%\n",
            "Number of labels = 4 in val dataset as percentage: 2.67%\n"
          ]
        }
      ],
      "source": [
        "X = X_train_ngram_bow_preproc_bow_kmeans.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_ngram_bow_preproc_bow_kmeans[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_ngram_bow_preproc_bow, y_val)\n",
        "run_sgd(X, y, X_val_ngram_bow_preproc_bow, y_val)\n",
        "run_knn(X, y, X_val_ngram_bow_preproc_bow, y_val)\n",
        "# run_random_forest(X, y, X_val_ngram_bow_preproc_bow, y_val)\n",
        "\n",
        "X = X_train_ngram_cntvec_preproc_cntvec_kmeans.drop(AUGMENTED_LABEL, axis=1)\n",
        "y = X_train_ngram_cntvec_preproc_cntvec_kmeans[AUGMENTED_LABEL]\n",
        "\n",
        "run_nb(X, y, X_val_ngram_cntvec_preproc_cntvec, y_val)\n",
        "run_sgd(X, y, X_val_ngram_cntvec_preproc_cntvec, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
